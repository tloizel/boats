name: Download GTFS Files and Convert to JSON

on:
  schedule:
    - cron: '0 0 * * *'  # This will run daily at midnight UTC
  workflow_dispatch:  # This allows manual trigger from GitHub UI

jobs:
  download-and-convert-gtfs:
    runs-on: ubuntu-latest  # Use the latest Ubuntu runner

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        pip install requests zipfile38 pandas

    - name: Download GTFS ZIP file
      run: |
        import requests
        import zipfile
        import os
        
        # URL for the GTFS zip file
        url = "http://nycferry.connexionz.net/rtt/public/utility/gtfs.aspx"
        zip_file_path = "gtfs_data.zip"
        
        # Download the GTFS zip file
        response = requests.get(url)
        
        with open(zip_file_path, "wb") as f:
            f.write(response.content)

    - name: Extract GTFS ZIP file
      run: |
        import zipfile
        import os
        
        # Extract the files from the zip archive
        zip_file_path = "gtfs_data.zip"
        extract_folder = "gtfs_files"
        
        # Create extraction folder if it doesn't exist
        if not os.path.exists(extract_folder):
            os.makedirs(extract_folder)
        
        # Extract files
        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
            zip_ref.extractall(extract_folder)

    - name: Convert GTFS files to JSON
      run: |
        import os
        import json
        import pandas as pd
        
        # Folder where the GTFS files are extracted
        gtfs_folder = "gtfs_files"
        
        # Convert each GTFS file into JSON
        for file_name in os.listdir(gtfs_folder):
            file_path = os.path.join(gtfs_folder, file_name)
            if file_name.endswith(".txt"):  # Only process text files (GTFS files)
                df = pd.read_csv(file_path)
                json_data = df.to_json(orient="records", lines=True)  # Convert to JSON
                
                # Write to a JSON file
                json_file_name = f"{file_name.replace('.txt', '.json')}"
                with open(f"{gtfs_folder}/{json_file_name}", "w") as json_file:
                    json_file.write(json_data)

    - name: Commit and push the GTFS JSON files
      uses: EndBug/add-and-commit@v7
      with:
        author_name: 'GitHub Actions'
        author_email: 'actions@github.com'
        message: 'Update GTFS data as JSON files'
